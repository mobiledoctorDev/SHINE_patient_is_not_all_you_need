{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#%%\nimport pandas as pd\nimport warnings\nimport os\nimport datetime\nimport gc\nfrom tqdm.auto import tqdm\nimport shutil, random\nimport pickle\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nos.umask(0)\n\n# from pandarallel import pandarallel\n# pandarallel.initialize(nb_workers=4, progress_bar=True)\n\n#%%\ndef iter_chunk_by_id(file):\n    csv_reader = pd.read_csv(file, iterator=True, chunksize=1)\n    first_chunk = csv_reader.get_chunk()\n    _id = first_chunk.iloc[0, 1]\n    chunk = pd.DataFrame(first_chunk)\n    for row in csv_reader:\n        if _id == row.iloc[0, 1]:\n            _id = row.iloc[0, 1]\n            chunk = chunk.append(row)\n            continue\n        _id = row.iloc[0, 1]\n        yield chunk\n        chunk = pd.DataFrame(row)\n    yield chunk\n\n\n#%%\ndef epinum_assign(g):\n    g = g.sort_values('date').reset_index(drop=True)\n    time_gap = [pd.to_datetime(g['date'].tolist()[x + 1]) - pd.to_datetime(g['date'].tolist()[x]) for x in\n                range(len(g['date'].tolist()) - 1)]\n    sep = [k for k, v in enumerate(time_gap) if v > pd.Timedelta('72h')]\n    sep = sorted(set(sep + [0, len(g.index)]))\n\n    end = 0\n    for epi_num, pos in enumerate(sep):\n        if pos < len(g.index):\n            # print(g.index[end:sep[epi_num+1]+1])\n            g.at[g.index[end:sep[epi_num + 1] + 1], 'epi_num'] = epi_num + 1\n            end = sep[epi_num + 1] + 1\n\n    g['data_1'] = g['data_1'].astype(str)\n    return g","metadata":{"_uuid":"1ce15c29-95f5-4c96-9124-5786feee8d91","_cell_guid":"b0cd6b7e-cf85-4554-9638-d3938e50d3d4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_and_save(epi_num_assigned):\n    for k, g in (epi_num_assigned.groupby(['baby_id', 'epi_num'])):\n        if not g.loc[(g['type'] == 4) & (g['data_1'] == '3')].empty:\n            single_case = []\n\n            if not g.loc[(g['type'] == 1)].empty:  # 체온\n                for idx, _temp_dict in enumerate(g.loc[(g['type'] == 1)].to_dict('records')):\n                    try:\n                        if not str(_temp_dict['data_2']).lower() == 'f':\n                            single_case.append([_temp_dict['date'], 'body_temperature', float(_temp_dict['data_1'])])\n                    except:\n                        print(_temp_dict)\n                    # data_2 = c/f, #data_3 = nfc/hs/dot, #data_4 = 0ear,1ax,2oral, #data_5: covid_vac, #lat, #lng, #weight\n                    # 화씨는 버리는걸로 / 귀or null? / data_5 무시\n\n            _type_dict = {'0': 'antipyretic', '1': 'other_drugs', '2': 'antibiotics'}\n            if not g.loc[(g['type'] == 2)].empty:  # 해열제\n                for idx, _temp_dict in enumerate(g.loc[(g['type'] == 2)].to_dict('records')):\n                    try:\n                        single_case.append([_temp_dict['date'], _type_dict[str(int(float(_temp_dict['data_1'])))],\n                                            float(_temp_dict['data_2'])])\n                    except:\n                        print(_temp_dict)\n                    # data_4 1:acet, 2:ibu, 3:dexi, #data_6 covid drug #drug_formulation 1 liquid, 2powder, 3, #convulsion\n                    ##알약인 애들만 모아서 용량 분포\n                    ##성분 무시\n\n            if not g.loc[(g['type'] == 101)].empty:  # covid\n                for idx, _temp_dict in enumerate(g.loc[(g['type'] == 2)].to_dict('records')):\n                    if not _temp_dict['data_1'] == 0:\n                        single_case.append([_temp_dict['date'], 'covid_diag', float(_temp_dict['data_1'])])\n\n            _type_dict = {'1': 'symptom', '2': 'antibiotics', '3': 'diagnosis', '4': 'daily_records',\n                          '5': 'vaccination'}\n            if not g.loc[(g['type'] == 4)].empty:  # 메모\n                for idx, _temp_dict in enumerate(g.loc[(g['type'] == 4)].to_dict('records')):\n                    try:\n                        if not _type_dict[str(int(float(_temp_dict['data_1'])))] == 'symptom':\n                            single_case.append([_temp_dict['date'], _type_dict[str(int(float(_temp_dict['data_1'])))],\n                                                float(_temp_dict['data_2'])])\n                        else:\n                            for vals in str(_temp_dict['data_2']).split('_'):\n                                single_case.append(\n                                    [_temp_dict['date'], f\"{_type_dict[str(int(float(_temp_dict['data_1'])))]}_{vals}\", 1])\n\n                    except:\n                        print(_temp_dict)\n\n\n            if '8' in g.loc[(g['type'] == 4) & (g['data_1'] == '3'), 'data_2'].values:\n                label = 'flu'\n            else:\n                label = 'notflu'\n\n            _type_dict = {'flu': 1, 'notflu': 0}\n            physionet_style_df = pd.DataFrame(single_case, columns=['time', 'var_name', 'value']).sort_values('time')\n\n            #weather_ref = pd.read_csv('./OBS_ASOS_DD_20211209143339.csv')\n\n            try:\n                #weather_date = pd.to_datetime(min(g['date'])).date()\n                age_val = (pd.to_datetime(min(physionet_style_df['time'])) - pd.to_datetime(_temp_dict['birthday'])).days\n                onetime_vars = pd.DataFrame([[max(physionet_style_df['time']), 'gender', _temp_dict['gender']],\n                                             [max(physionet_style_df['time']), 'age', age_val],\n                                             [max(physionet_style_df['time']), 'weight', _temp_dict['weight']],\n                                             [max(physionet_style_df['time']), 'convulsion', _temp_dict['convulsion']],\n                                             [max(physionet_style_df['time']), 'is_flu', _type_dict[label]]],\n                                            columns=['time', 'var_name', 'value'])\n                physionet_style_df = physionet_style_df.append(onetime_vars)\n                physionet_style_df['time'] = physionet_style_df['time'] - min(physionet_style_df['time'])\n                physionet_style_df = physionet_style_df.loc[~physionet_style_df['var_name'].isin(['is_flu', 'diagnosis'])]\n                physionet_style_df['time'] = (pd.to_datetime(physionet_style_df['time']) - pd.to_datetime(min(physionet_style_df['time'])))\n                physionet_style_df = physionet_style_df.sort_values(by=['time'])\n                physionet_style_df['time'] = physionet_style_df['time'].apply(lambda x: convert(x.total_seconds()))\n                physionet_style_df = physionet_style_df.dropna().reset_index(drop=True)\n\n                inputdict_col_append(df['var_name'].unique().tolist())\n                label_col_append([os.path.splitext(file)[0], _type_dict[label]])\n                date_col_append(weather_date)\n\n                #print(weather_ref.loc[weather_ref['date'] == weather_date])\n                physionet_style_df.to_csv(f\"{root_path}/{label}/{k[0]}_{int(k[1])}.csv\", index=False)\n            except:\n                pass","metadata":{"_uuid":"9b03c599-7981-44ee-b432-c6206661c6c8","_cell_guid":"218ff5e2-2b90-481c-b359-0c20a2bffd5b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert(seconds):\n    #seconds = seconds % (24 * 3600)\n    hour = seconds // 3600\n    seconds %= 3600\n    minutes = seconds // 60\n    seconds %= 60\n\n    return \"%02d:%02d:%02d\" % (hour, minutes, seconds)\n#%%\nroot_path = f\"./v2_episode/{str(datetime.datetime.now()).split(' ')[0]}\"\n\nif not (os.path.exists(f'{root_path}/flu')):\n    os.makedirs(f'{root_path}/flu')\n\nif not (os.path.exists(f'{root_path}/notflu')):\n    os.makedirs(f'{root_path}/notflu')","metadata":{"_uuid":"2e48e062-827e-44ca-9768-f8e601e3be2b","_cell_guid":"25ae8bf4-dae7-42b5-98b8-36797de9f296","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#chunk_iter = iter_chunk_by_id(\"/opt/project/md_data__with_baby_having_dx_sorted.csv\")\ndf =  pd.read_csv(\"/opt/project/md_data__with_baby_having_dx_sorted.csv\", \\\n                  usecols=['baby_id', 'date', 'type', 'data_1', 'data_2', 'gender', 'birthday', 'weight', 'convulsion' ])\n\n#weather_ref = pd.read_csv('./OBS_ASOS_DD_20211209143339.csv')\n\ndate_collector = []\ninputdict_collector = []\nlabel_collector = []\n\ndate_col_append = date_collector.append\nlabel_col_append = label_collector.append\ninputdict_col_append = inputdict_collector.append\n\nfor no, chunk in tqdm(df.groupby('baby_id')):\n    if not chunk.loc[(chunk['type']==4) & (chunk['data_1']=='3')].empty:\n        extract_and_save(epinum_assign(chunk))\n        gc.collect()\n\npd.DataFrame(labels).to_csv('/opt/project/v2_episode/labels.csv', index=False, encoding='utf-8-sig')\nwith open('/opt/project/v2_episode/inputdict.p', 'wb') as handle:\n    pickle.dump(set(list(itertools.chain(*temp_list))), handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"_uuid":"805c195c-8858-4a78-b3da-3d4f345bf221","_cell_guid":"f8a5ed09-c5a5-4b3e-acb4-4fbeb96c20ff","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}